{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "import keras \n",
    "from keras.layers.merge import Grad \n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the data \n",
    "import h5py \n",
    "import numpy as np \n",
    "data_prefix=\"/srv/scratch/annashch/deeplearning/gradient_exp/\"\n",
    "train_hdf5=h5py.File(data_prefix+\"train_data.hdf5\",'r')\n",
    "train_X=train_hdf5['X']['sequence']\n",
    "train_Y=train_hdf5['Y']['output']\n",
    "\n",
    "valid_hdf5=h5py.File(data_prefix+'valid_data.hdf5','r')\n",
    "valid_X=valid_hdf5['X']['sequence']\n",
    "valid_Y=valid_hdf5['Y']['output']\n",
    "\n",
    "test_hdf5=h5py.File(data_prefix+\"test_data.hdf5\",'r')\n",
    "test_X=test_hdf5['X']['sequence']\n",
    "test_Y=test_hdf5['Y']['output']\n",
    "\n",
    "weights=np.load('weights.npy')\n",
    "Y_grads=np.load('gradients.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build the model -- without gradient reward (this is our baseline)\n",
    "input_shape=(200,4)\n",
    "pool_size=10 \n",
    "inp = keras.layers.Input(shape=input_shape)\n",
    "conv = keras.layers.Convolution1D(nb_filter=15, filter_length=15, subsample_length=1)(inp)\n",
    "relu_post_conv = keras.layers.Activation(\"relu\")(conv)\n",
    "gap = keras.layers.pooling.GlobalAveragePooling1D()(relu_post_conv)\n",
    "dense = keras.layers.Dense(2)(gap)\n",
    "sigmoid_out = keras.layers.Activation(\"sigmoid\")(dense)\n",
    "model = keras.models.Model(input=inp, output=sigmoid_out)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",metrics=[\"binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train the model \n",
    "model_output_path=\"benchmarkModel\"\n",
    "#checkpointer = ModelCheckpoint(filepath=model_output_path)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "tensorboard = TensorBoard( write_images=True)\n",
    "csv_logger = CSVLogger('training.benchmark.log')\n",
    "model.fit(x=np.asarray(train_X), \n",
    "          y=np.asarray(train_Y),\n",
    "          callbacks=[earlystopper,csv_logger,tensorboard],\n",
    "          batch_size=250,\n",
    "          epochs=50,\n",
    "          validation_data=tuple([valid_X,valid_Y]),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/annashch/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(strides=1, filters=15, kernel_size=15)`\n",
      "/users/annashch/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "#build the model with gradient reward \n",
    "reload(keras.layers.merge)\n",
    "from keras.layers.merge import Grad\n",
    "input_shape=(200,4)\n",
    "pool_size=10 \n",
    "inp = keras.layers.Input(shape=input_shape)\n",
    "conv = keras.layers.Convolution1D(nb_filter=15, filter_length=15, subsample_length=1)(inp)\n",
    "relu_post_conv = keras.layers.Activation(\"relu\")(conv)\n",
    "gap = keras.layers.pooling.GlobalAveragePooling1D()(relu_post_conv)\n",
    "dense = keras.layers.Dense(2)(gap)\n",
    "sigmoid_out = keras.layers.Activation(\"sigmoid\")(dense)\n",
    "grad_layer1 = Grad(task_index=0)([inp, dense])\n",
    "grad_layer2 = Grad(task_index=1)([inp, dense])\n",
    "model_grad = keras.models.Model(input=inp, output=[sigmoid_out, grad_layer1,grad_layer2])\n",
    "model_grad.compile(sample_weight_mode=[None,\"temporal\",\"temporal\"],optimizer=\"adam\", loss=[\"binary_crossentropy\",keras.losses.get_positionwise_cosine_1d(pool_size=pool_size),keras.losses.get_positionwise_cosine_1d(pool_size=pool_size)],metrics=[\"binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train the model \n",
    "model_output_path=\"gradModel\"\n",
    "#checkpointer = ModelCheckpoint(filepath=model_output_path)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "tensorboard = TensorBoard( write_images=True)\n",
    "csv_logger = CSVLogger('training.grad.log')\n",
    "model_grad.fit(x=np.asarray(train_X), \n",
    "          y=np.asarray(train_Y),\n",
    "          callbacks=[earlystopper,csv_logger,tensorboard],\n",
    "          batch_size=250,\n",
    "          epochs=50,\n",
    "          validation_data=tuple([valid_X,valid_Y]),\n",
    "          verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
