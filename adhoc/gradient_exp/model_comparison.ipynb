{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "import keras \n",
    "from keras.layers.merge import Grad \n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the data \n",
    "import h5py \n",
    "import numpy as np \n",
    "data_prefix=\"/srv/scratch/annashch/deeplearning/gradient_exp/\"\n",
    "train_hdf5=h5py.File(data_prefix+\"train_data.hdf5\",'r')\n",
    "train_X=train_hdf5['X']['sequence']\n",
    "train_Y=train_hdf5['Y']['output']\n",
    "\n",
    "valid_hdf5=h5py.File(data_prefix+'valid_data.hdf5','r')\n",
    "valid_X=valid_hdf5['X']['sequence']\n",
    "valid_Y=valid_hdf5['Y']['output']\n",
    "\n",
    "test_hdf5=h5py.File(data_prefix+\"test_data.hdf5\",'r')\n",
    "test_X=test_hdf5['X']['sequence']\n",
    "test_Y=test_hdf5['Y']['output']\n",
    "\n",
    "weights_gata=np.load('weights_gata.npy')\n",
    "Y_grads_gata=np.load('gradients_gata.npy')\n",
    "weights_tal=np.load('weights_tal.npy')\n",
    "Y_grads_tal=np.load('gradients_tal.npy')\n",
    "weights_gata_valid=np.load('weights_gata_valid.npy')\n",
    "Y_grads_gata_valid=np.load('gradients_gata_valid.npy')\n",
    "weights_tal_valid=np.load('weights_tal_valid.npy')\n",
    "Y_grads_tal_valid=np.load('gradients_tal_valid.npy')\n",
    "weights_gata_test=np.load('weights_gata_test.npy')\n",
    "Y_grads_gata_test=np.load('gradients_gata_test.npy')\n",
    "weights_tal_test=np.load('weights_tal_test.npy')\n",
    "Y_grads_tal_test=np.load('gradients_tal_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/annashch/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(strides=1, filters=15, kernel_size=15)`\n",
      "/users/annashch/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "#build the model -- without gradient reward (this is our baseline)\n",
    "input_shape=(200,4)\n",
    "pool_size=10 \n",
    "inp = keras.layers.Input(shape=input_shape)\n",
    "conv = keras.layers.Convolution1D(nb_filter=15, filter_length=15, subsample_length=1)(inp)\n",
    "relu_post_conv = keras.layers.Activation(\"relu\")(conv)\n",
    "gap = keras.layers.pooling.GlobalAveragePooling1D()(relu_post_conv)\n",
    "dense = keras.layers.Dense(2)(gap)\n",
    "sigmoid_out = keras.layers.Activation(\"sigmoid\")(dense)\n",
    "model = keras.models.Model(input=inp, output=sigmoid_out)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",metrics=[\"binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 300 samples\n",
      "Epoch 1/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6833 - binary_accuracy: 0.6200 - val_loss: 0.6700 - val_binary_accuracy: 0.6500\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6567 - binary_accuracy: 0.6679 - val_loss: 0.6514 - val_binary_accuracy: 0.6500\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6399 - binary_accuracy: 0.6679 - val_loss: 0.6452 - val_binary_accuracy: 0.6500\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6346 - binary_accuracy: 0.6679 - val_loss: 0.6466 - val_binary_accuracy: 0.6500\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6341 - binary_accuracy: 0.6679 - val_loss: 0.6470 - val_binary_accuracy: 0.6500\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6337 - binary_accuracy: 0.6679 - val_loss: 0.6457 - val_binary_accuracy: 0.6500\n",
      "Epoch 7/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6331 - binary_accuracy: 0.6679 - val_loss: 0.6442 - val_binary_accuracy: 0.6500\n",
      "Epoch 8/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6327 - binary_accuracy: 0.6679 - val_loss: 0.6436 - val_binary_accuracy: 0.6500\n",
      "Epoch 9/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6324 - binary_accuracy: 0.6679 - val_loss: 0.6430 - val_binary_accuracy: 0.6500\n",
      "Epoch 10/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6324 - binary_accuracy: 0.6679 - val_loss: 0.6429 - val_binary_accuracy: 0.6500\n",
      "Epoch 11/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6317 - binary_accuracy: 0.6679 - val_loss: 0.6421 - val_binary_accuracy: 0.6500\n",
      "Epoch 12/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6315 - binary_accuracy: 0.6679 - val_loss: 0.6411 - val_binary_accuracy: 0.6500\n",
      "Epoch 13/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6307 - binary_accuracy: 0.6679 - val_loss: 0.6413 - val_binary_accuracy: 0.6500\n",
      "Epoch 14/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6306 - binary_accuracy: 0.6679 - val_loss: 0.6406 - val_binary_accuracy: 0.6500\n",
      "Epoch 15/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6303 - binary_accuracy: 0.6679 - val_loss: 0.6395 - val_binary_accuracy: 0.6500\n",
      "Epoch 16/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6297 - binary_accuracy: 0.6679 - val_loss: 0.6393 - val_binary_accuracy: 0.6500\n",
      "Epoch 17/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6292 - binary_accuracy: 0.6679 - val_loss: 0.6382 - val_binary_accuracy: 0.6500\n",
      "Epoch 18/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6288 - binary_accuracy: 0.6679 - val_loss: 0.6376 - val_binary_accuracy: 0.6500\n",
      "Epoch 19/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6283 - binary_accuracy: 0.6679 - val_loss: 0.6369 - val_binary_accuracy: 0.6500\n",
      "Epoch 20/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6279 - binary_accuracy: 0.6679 - val_loss: 0.6363 - val_binary_accuracy: 0.6500\n",
      "Epoch 21/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6275 - binary_accuracy: 0.6679 - val_loss: 0.6359 - val_binary_accuracy: 0.6500\n",
      "Epoch 22/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6273 - binary_accuracy: 0.6679 - val_loss: 0.6348 - val_binary_accuracy: 0.6500\n",
      "Epoch 23/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6266 - binary_accuracy: 0.6679 - val_loss: 0.6341 - val_binary_accuracy: 0.6500\n",
      "Epoch 24/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6261 - binary_accuracy: 0.6679 - val_loss: 0.6332 - val_binary_accuracy: 0.6500\n",
      "Epoch 25/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6258 - binary_accuracy: 0.6679 - val_loss: 0.6327 - val_binary_accuracy: 0.6500\n",
      "Epoch 26/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6253 - binary_accuracy: 0.6679 - val_loss: 0.6322 - val_binary_accuracy: 0.6500\n",
      "Epoch 27/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6248 - binary_accuracy: 0.6679 - val_loss: 0.6312 - val_binary_accuracy: 0.6500\n",
      "Epoch 28/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6245 - binary_accuracy: 0.6679 - val_loss: 0.6305 - val_binary_accuracy: 0.6500\n",
      "Epoch 29/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6241 - binary_accuracy: 0.6679 - val_loss: 0.6298 - val_binary_accuracy: 0.6500\n",
      "Epoch 30/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6238 - binary_accuracy: 0.6679 - val_loss: 0.6297 - val_binary_accuracy: 0.6500\n",
      "Epoch 31/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6233 - binary_accuracy: 0.6679 - val_loss: 0.6288 - val_binary_accuracy: 0.6500\n",
      "Epoch 32/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6229 - binary_accuracy: 0.6679 - val_loss: 0.6279 - val_binary_accuracy: 0.6500\n",
      "Epoch 33/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6228 - binary_accuracy: 0.6679 - val_loss: 0.6270 - val_binary_accuracy: 0.6500\n",
      "Epoch 34/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6224 - binary_accuracy: 0.6679 - val_loss: 0.6273 - val_binary_accuracy: 0.6500\n",
      "Epoch 35/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6222 - binary_accuracy: 0.6679 - val_loss: 0.6258 - val_binary_accuracy: 0.6500\n",
      "Epoch 36/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6214 - binary_accuracy: 0.6679 - val_loss: 0.6253 - val_binary_accuracy: 0.6500\n",
      "Epoch 37/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6215 - binary_accuracy: 0.6681 - val_loss: 0.6248 - val_binary_accuracy: 0.6500\n",
      "Epoch 38/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6213 - binary_accuracy: 0.6679 - val_loss: 0.6240 - val_binary_accuracy: 0.6500\n",
      "Epoch 39/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6202 - binary_accuracy: 0.6679 - val_loss: 0.6240 - val_binary_accuracy: 0.6500\n",
      "Epoch 40/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6203 - binary_accuracy: 0.6683 - val_loss: 0.6235 - val_binary_accuracy: 0.6500\n",
      "Epoch 41/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6198 - binary_accuracy: 0.6681 - val_loss: 0.6225 - val_binary_accuracy: 0.6500\n",
      "Epoch 42/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6196 - binary_accuracy: 0.6679 - val_loss: 0.6215 - val_binary_accuracy: 0.6517\n",
      "Epoch 43/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6193 - binary_accuracy: 0.6683 - val_loss: 0.6214 - val_binary_accuracy: 0.6517\n",
      "Epoch 44/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6189 - binary_accuracy: 0.6688 - val_loss: 0.6209 - val_binary_accuracy: 0.6517\n",
      "Epoch 45/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6188 - binary_accuracy: 0.6681 - val_loss: 0.6203 - val_binary_accuracy: 0.6517\n",
      "Epoch 46/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6183 - binary_accuracy: 0.6688 - val_loss: 0.6194 - val_binary_accuracy: 0.6517\n",
      "Epoch 47/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6180 - binary_accuracy: 0.6690 - val_loss: 0.6189 - val_binary_accuracy: 0.6517\n",
      "Epoch 48/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6179 - binary_accuracy: 0.6698 - val_loss: 0.6187 - val_binary_accuracy: 0.6517\n",
      "Epoch 49/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6174 - binary_accuracy: 0.6692 - val_loss: 0.6177 - val_binary_accuracy: 0.6517\n",
      "Epoch 50/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6170 - binary_accuracy: 0.6696 - val_loss: 0.6176 - val_binary_accuracy: 0.6517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f192291b110>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model \n",
    "model_output_path=\"benchmarkModel\"\n",
    "#checkpointer = ModelCheckpoint(filepath=model_output_path)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "tensorboard = TensorBoard( write_images=True)\n",
    "csv_logger = CSVLogger('training.benchmark.log')\n",
    "model.fit(x=np.asarray(train_X), \n",
    "          y=np.asarray(train_Y),\n",
    "          callbacks=[earlystopper,csv_logger,tensorboard],\n",
    "          batch_size=250,\n",
    "          epochs=50,\n",
    "          validation_data=tuple([valid_X,valid_Y]),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/annashch/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(strides=1, filters=15, kernel_size=15)`\n",
      "/users/annashch/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "#build the model with gradient reward \n",
    "reload(keras.layers.merge)\n",
    "from keras.layers.merge import Grad\n",
    "input_shape=(200,4)\n",
    "pool_size=10 \n",
    "inp = keras.layers.Input(shape=input_shape)\n",
    "conv = keras.layers.Convolution1D(nb_filter=15, filter_length=15, subsample_length=1)(inp)\n",
    "relu_post_conv = keras.layers.Activation(\"relu\")(conv)\n",
    "gap = keras.layers.pooling.GlobalAveragePooling1D()(relu_post_conv)\n",
    "dense = keras.layers.Dense(2)(gap)\n",
    "sigmoid_out = keras.layers.Activation(\"sigmoid\")(dense)\n",
    "grad_layer1 = Grad(task_index=0)([inp, dense])\n",
    "grad_layer2 = Grad(task_index=1)([inp, dense])\n",
    "model_grad = keras.models.Model(input=inp, output=[sigmoid_out, grad_layer1,grad_layer2])\n",
    "model_grad.compile(sample_weight_mode=[None,\"temporal\",\"temporal\"],\n",
    "                   optimizer=\"adam\", \n",
    "                   loss=[\"binary_crossentropy\",\n",
    "                         keras.losses.get_positionwise_cosine_1d(pool_size=pool_size),\n",
    "                         keras.losses.get_positionwise_cosine_1d(pool_size=pool_size)],\n",
    "                   metrics=[\"binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 300 samples\n",
      "Epoch 1/50\n",
      "2400/2400 [==============================] - 0s - loss: -0.1882 - activation_2_loss: 0.6345 - grad_1_loss: -0.4475 - grad_2_loss: -0.3752 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: -0.1664 - val_activation_2_loss: 0.6458 - val_grad_1_loss: -0.4426 - val_grad_2_loss: -0.3697 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 0s - loss: -0.1647 - activation_2_loss: 0.6340 - grad_1_loss: -0.4339 - grad_2_loss: -0.3648 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: -0.1219 - val_activation_2_loss: 0.6453 - val_grad_1_loss: -0.4106 - val_grad_2_loss: -0.3566 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 0s - loss: -0.0515 - activation_2_loss: 0.6339 - grad_1_loss: -0.3281 - grad_2_loss: -0.3573 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.0852 - val_activation_2_loss: 0.6449 - val_grad_1_loss: -0.2207 - val_grad_2_loss: -0.3390 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.1740 - activation_2_loss: 0.6329 - grad_1_loss: -0.1812 - grad_2_loss: -0.2777 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.2943 - val_activation_2_loss: 0.6436 - val_grad_1_loss: -0.1389 - val_grad_2_loss: -0.2105 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.3369 - activation_2_loss: 0.6326 - grad_1_loss: -0.1189 - grad_2_loss: -0.1768 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.3704 - val_activation_2_loss: 0.6432 - val_grad_1_loss: -0.0980 - val_grad_2_loss: -0.1748 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.3635 - activation_2_loss: 0.6322 - grad_1_loss: -0.0858 - grad_2_loss: -0.1829 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.3797 - val_activation_2_loss: 0.6432 - val_grad_1_loss: -0.0812 - val_grad_2_loss: -0.1824 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 7/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.3830 - activation_2_loss: 0.6316 - grad_1_loss: -0.0814 - grad_2_loss: -0.1672 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.3982 - val_activation_2_loss: 0.6419 - val_grad_1_loss: -0.0849 - val_grad_2_loss: -0.1588 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 8/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.3898 - activation_2_loss: 0.6312 - grad_1_loss: -0.0845 - grad_2_loss: -0.1570 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.3985 - val_activation_2_loss: 0.6411 - val_grad_1_loss: -0.0827 - val_grad_2_loss: -0.1599 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 9/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.3882 - activation_2_loss: 0.6310 - grad_1_loss: -0.0833 - grad_2_loss: -0.1594 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.3980 - val_activation_2_loss: 0.6405 - val_grad_1_loss: -0.0806 - val_grad_2_loss: -0.1619 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 10/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.3922 - activation_2_loss: 0.6306 - grad_1_loss: -0.0740 - grad_2_loss: -0.1644 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.4011 - val_activation_2_loss: 0.6402 - val_grad_1_loss: -0.0741 - val_grad_2_loss: -0.1651 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 11/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.3918 - activation_2_loss: 0.6300 - grad_1_loss: -0.0720 - grad_2_loss: -0.1662 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.4016 - val_activation_2_loss: 0.6397 - val_grad_1_loss: -0.0714 - val_grad_2_loss: -0.1667 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 12/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.3940 - activation_2_loss: 0.6295 - grad_1_loss: -0.0689 - grad_2_loss: -0.1667 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.4112 - val_activation_2_loss: 0.6385 - val_grad_1_loss: -0.0601 - val_grad_2_loss: -0.1671 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 13/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.4487 - activation_2_loss: 0.6291 - grad_1_loss: -0.0125 - grad_2_loss: -0.1679 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.5041 - val_activation_2_loss: 0.6379 - val_grad_1_loss: 0.0346 - val_grad_2_loss: -0.1684 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 14/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.5005 - activation_2_loss: 0.6288 - grad_1_loss: 0.0396 - grad_2_loss: -0.1680 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.5655 - val_activation_2_loss: 0.6376 - val_grad_1_loss: 0.0968 - val_grad_2_loss: -0.1689 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 15/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.5727 - activation_2_loss: 0.6286 - grad_1_loss: 0.1124 - grad_2_loss: -0.1683 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6235 - val_activation_2_loss: 0.6370 - val_grad_1_loss: 0.1568 - val_grad_2_loss: -0.1702 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 16/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6243 - activation_2_loss: 0.6279 - grad_1_loss: 0.1661 - grad_2_loss: -0.1697 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6301 - val_activation_2_loss: 0.6362 - val_grad_1_loss: 0.1631 - val_grad_2_loss: -0.1692 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 17/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6337 - activation_2_loss: 0.6276 - grad_1_loss: 0.1760 - grad_2_loss: -0.1698 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6424 - val_activation_2_loss: 0.6354 - val_grad_1_loss: 0.1766 - val_grad_2_loss: -0.1696 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 18/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6352 - activation_2_loss: 0.6274 - grad_1_loss: 0.1770 - grad_2_loss: -0.1692 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6405 - val_activation_2_loss: 0.6350 - val_grad_1_loss: 0.1741 - val_grad_2_loss: -0.1686 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 19/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6395 - activation_2_loss: 0.6267 - grad_1_loss: 0.1832 - grad_2_loss: -0.1704 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6492 - val_activation_2_loss: 0.6349 - val_grad_1_loss: 0.1859 - val_grad_2_loss: -0.1717 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 20/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6421 - activation_2_loss: 0.6265 - grad_1_loss: 0.1872 - grad_2_loss: -0.1716 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6485 - val_activation_2_loss: 0.6339 - val_grad_1_loss: 0.1851 - val_grad_2_loss: -0.1704 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 21/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6417 - activation_2_loss: 0.6265 - grad_1_loss: 0.1838 - grad_2_loss: -0.1686 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6480 - val_activation_2_loss: 0.6329 - val_grad_1_loss: 0.1840 - val_grad_2_loss: -0.1689 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 22/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6427 - activation_2_loss: 0.6259 - grad_1_loss: 0.1867 - grad_2_loss: -0.1698 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6493 - val_activation_2_loss: 0.6327 - val_grad_1_loss: 0.1869 - val_grad_2_loss: -0.1702 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 23/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6426 - activation_2_loss: 0.6254 - grad_1_loss: 0.1884 - grad_2_loss: -0.1713 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6494 - val_activation_2_loss: 0.6328 - val_grad_1_loss: 0.1875 - val_grad_2_loss: -0.1709 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 24/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6427 - activation_2_loss: 0.6253 - grad_1_loss: 0.1868 - grad_2_loss: -0.1694 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6484 - val_activation_2_loss: 0.6315 - val_grad_1_loss: 0.1859 - val_grad_2_loss: -0.1689 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 25/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6429 - activation_2_loss: 0.6249 - grad_1_loss: 0.1880 - grad_2_loss: -0.1700 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6486 - val_activation_2_loss: 0.6311 - val_grad_1_loss: 0.1883 - val_grad_2_loss: -0.1708 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 26/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6425 - activation_2_loss: 0.6243 - grad_1_loss: 0.1885 - grad_2_loss: -0.1703 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6482 - val_activation_2_loss: 0.6302 - val_grad_1_loss: 0.1880 - val_grad_2_loss: -0.1700 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 27/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6424 - activation_2_loss: 0.6239 - grad_1_loss: 0.1892 - grad_2_loss: -0.1707 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6485 - val_activation_2_loss: 0.6302 - val_grad_1_loss: 0.1893 - val_grad_2_loss: -0.1710 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 28/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6425 - activation_2_loss: 0.6235 - grad_1_loss: 0.1895 - grad_2_loss: -0.1705 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6482 - val_activation_2_loss: 0.6293 - val_grad_1_loss: 0.1895 - val_grad_2_loss: -0.1705 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 29/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6431 - activation_2_loss: 0.6234 - grad_1_loss: 0.1910 - grad_2_loss: -0.1714 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6489 - val_activation_2_loss: 0.6293 - val_grad_1_loss: 0.1913 - val_grad_2_loss: -0.1717 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 30/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6437 - activation_2_loss: 0.6229 - grad_1_loss: 0.1908 - grad_2_loss: -0.1700 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6490 - val_activation_2_loss: 0.6277 - val_grad_1_loss: 0.1901 - val_grad_2_loss: -0.1688 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 31/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6442 - activation_2_loss: 0.6226 - grad_1_loss: 0.1914 - grad_2_loss: -0.1698 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6493 - val_activation_2_loss: 0.6278 - val_grad_1_loss: 0.1924 - val_grad_2_loss: -0.1709 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 32/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6442 - activation_2_loss: 0.6220 - grad_1_loss: 0.1931 - grad_2_loss: -0.1710 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6488 - val_activation_2_loss: 0.6268 - val_grad_1_loss: 0.1923 - val_grad_2_loss: -0.1703 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 33/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6443 - activation_2_loss: 0.6217 - grad_1_loss: 0.1922 - grad_2_loss: -0.1695 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6486 - val_activation_2_loss: 0.6257 - val_grad_1_loss: 0.1919 - val_grad_2_loss: -0.1690 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 34/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6450 - activation_2_loss: 0.6216 - grad_1_loss: 0.1929 - grad_2_loss: -0.1695 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6493 - val_activation_2_loss: 0.6255 - val_grad_1_loss: 0.1935 - val_grad_2_loss: -0.1698 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 35/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6453 - activation_2_loss: 0.6211 - grad_1_loss: 0.1949 - grad_2_loss: -0.1707 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6502 - val_activation_2_loss: 0.6256 - val_grad_1_loss: 0.1948 - val_grad_2_loss: -0.1703 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 36/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6457 - activation_2_loss: 0.6208 - grad_1_loss: 0.1953 - grad_2_loss: -0.1703 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6498 - val_activation_2_loss: 0.6244 - val_grad_1_loss: 0.1947 - val_grad_2_loss: -0.1693 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 37/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6461 - activation_2_loss: 0.6205 - grad_1_loss: 0.1958 - grad_2_loss: -0.1702 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6500 - val_activation_2_loss: 0.6243 - val_grad_1_loss: 0.1960 - val_grad_2_loss: -0.1703 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 38/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6461 - activation_2_loss: 0.6198 - grad_1_loss: 0.1962 - grad_2_loss: -0.1699 - activation_2_binary_accuracy: 0.6681 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6502 - val_activation_2_loss: 0.6232 - val_grad_1_loss: 0.1949 - val_grad_2_loss: -0.1679 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 39/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6477 - activation_2_loss: 0.6204 - grad_1_loss: 0.1946 - grad_2_loss: -0.1673 - activation_2_binary_accuracy: 0.6679 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6505 - val_activation_2_loss: 0.6224 - val_grad_1_loss: 0.1954 - val_grad_2_loss: -0.1673 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 40/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6469 - activation_2_loss: 0.6189 - grad_1_loss: 0.1969 - grad_2_loss: -0.1689 - activation_2_binary_accuracy: 0.6685 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6515 - val_activation_2_loss: 0.6235 - val_grad_1_loss: 0.1980 - val_grad_2_loss: -0.1701 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 41/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6477 - activation_2_loss: 0.6193 - grad_1_loss: 0.1981 - grad_2_loss: -0.1697 - activation_2_binary_accuracy: 0.6681 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6510 - val_activation_2_loss: 0.6223 - val_grad_1_loss: 0.1972 - val_grad_2_loss: -0.1685 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 42/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6478 - activation_2_loss: 0.6187 - grad_1_loss: 0.1972 - grad_2_loss: -0.1680 - activation_2_binary_accuracy: 0.6677 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6509 - val_activation_2_loss: 0.6208 - val_grad_1_loss: 0.1969 - val_grad_2_loss: -0.1668 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 43/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6485 - activation_2_loss: 0.6185 - grad_1_loss: 0.1979 - grad_2_loss: -0.1678 - activation_2_binary_accuracy: 0.6687 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6511 - val_activation_2_loss: 0.6208 - val_grad_1_loss: 0.1980 - val_grad_2_loss: -0.1677 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 44/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6487 - activation_2_loss: 0.6182 - grad_1_loss: 0.1979 - grad_2_loss: -0.1674 - activation_2_binary_accuracy: 0.6687 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6513 - val_activation_2_loss: 0.6201 - val_grad_1_loss: 0.1979 - val_grad_2_loss: -0.1666 - val_activation_2_binary_accuracy: 0.6500 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 45/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6494 - activation_2_loss: 0.6179 - grad_1_loss: 0.1988 - grad_2_loss: -0.1672 - activation_2_binary_accuracy: 0.6694 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6518 - val_activation_2_loss: 0.6196 - val_grad_1_loss: 0.1987 - val_grad_2_loss: -0.1664 - val_activation_2_binary_accuracy: 0.6517 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 46/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6500 - activation_2_loss: 0.6177 - grad_1_loss: 0.1996 - grad_2_loss: -0.1673 - activation_2_binary_accuracy: 0.6696 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6520 - val_activation_2_loss: 0.6193 - val_grad_1_loss: 0.1989 - val_grad_2_loss: -0.1662 - val_activation_2_binary_accuracy: 0.6517 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 47/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6502 - activation_2_loss: 0.6173 - grad_1_loss: 0.1989 - grad_2_loss: -0.1660 - activation_2_binary_accuracy: 0.6692 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6522 - val_activation_2_loss: 0.6184 - val_grad_1_loss: 0.1988 - val_grad_2_loss: -0.1650 - val_activation_2_binary_accuracy: 0.6517 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 48/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6508 - activation_2_loss: 0.6169 - grad_1_loss: 0.1999 - grad_2_loss: -0.1661 - activation_2_binary_accuracy: 0.6702 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6540 - val_activation_2_loss: 0.6190 - val_grad_1_loss: 0.2003 - val_grad_2_loss: -0.1654 - val_activation_2_binary_accuracy: 0.6533 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 49/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6522 - activation_2_loss: 0.6169 - grad_1_loss: 0.1995 - grad_2_loss: -0.1642 - activation_2_binary_accuracy: 0.6698 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6546 - val_activation_2_loss: 0.6174 - val_grad_1_loss: 0.1986 - val_grad_2_loss: -0.1614 - val_activation_2_binary_accuracy: 0.6517 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n",
      "Epoch 50/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6531 - activation_2_loss: 0.6162 - grad_1_loss: 0.1985 - grad_2_loss: -0.1615 - activation_2_binary_accuracy: 0.6700 - grad_1_binary_accuracy: 0.9376 - grad_2_binary_accuracy: 0.9494 - val_loss: 0.6552 - val_activation_2_loss: 0.6169 - val_grad_1_loss: 0.1981 - val_grad_2_loss: -0.1598 - val_activation_2_binary_accuracy: 0.6517 - val_grad_1_binary_accuracy: 0.9378 - val_grad_2_binary_accuracy: 0.9493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1980fd3710>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model \n",
    "model_output_path=\"gradModel\"\n",
    "#checkpointer = ModelCheckpoint(filepath=model_output_path)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "tensorboard = TensorBoard( write_images=True)\n",
    "csv_logger = CSVLogger('training.grad.log')\n",
    "model_grad.fit(x=np.asarray(train_X), \n",
    "          y=[np.asarray(train_Y),Y_grads_gata,Y_grads_tal],\n",
    "               sample_weight=[None,weights_gata,weights_tal],\n",
    "          callbacks=[csv_logger],\n",
    "               validation_data=tuple([valid_X,\n",
    "                                      [np.asarray(valid_Y),Y_grads_gata_valid,Y_grads_tal_valid],\n",
    "                                      [None,weights_gata_valid,weights_tal_valid]\n",
    "                                     ]),\n",
    "          batch_size=250,\n",
    "          epochs=50,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
