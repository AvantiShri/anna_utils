{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "\n",
    "import keras \n",
    "from keras.layers.merge import Grad \n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the data \n",
    "import h5py \n",
    "import numpy as np \n",
    "data_prefix=\"/srv/scratch/annashch/deeplearning/gradient_exp/\"\n",
    "train_hdf5=h5py.File(data_prefix+\"train_data.hdf5\",'r')\n",
    "train_X=train_hdf5['X']['sequence']\n",
    "train_Y=train_hdf5['Y']['output']\n",
    "\n",
    "valid_hdf5=h5py.File(data_prefix+'valid_data.hdf5','r')\n",
    "valid_X=valid_hdf5['X']['sequence']\n",
    "valid_Y=valid_hdf5['Y']['output']\n",
    "\n",
    "test_hdf5=h5py.File(data_prefix+\"test_data.hdf5\",'r')\n",
    "test_X=test_hdf5['X']['sequence']\n",
    "test_Y=test_hdf5['Y']['output']\n",
    "\n",
    "weights_gata=np.load('weights_gata_train.npy')\n",
    "Y_grads_gata=np.load('gradients_gata_train.npy')\n",
    "weights_tal=np.load('weights_tal_train.npy')\n",
    "Y_grads_tal=np.load('gradients_tal_train.npy')\n",
    "weights_gata_valid=np.load('weights_gata_valid.npy')\n",
    "Y_grads_gata_valid=np.load('gradients_gata_valid.npy')\n",
    "weights_tal_valid=np.load('weights_tal_valid.npy')\n",
    "Y_grads_tal_valid=np.load('gradients_tal_valid.npy')\n",
    "weights_gata_test=np.load('weights_gata_test.npy')\n",
    "Y_grads_gata_test=np.load('gradients_gata_test.npy')\n",
    "weights_tal_test=np.load('weights_tal_test.npy')\n",
    "Y_grads_tal_test=np.load('gradients_tal_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/annashch/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(strides=1, filters=10, kernel_size=10)`\n",
      "/users/annashch/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:9: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(strides=1, filters=10, kernel_size=30)`\n",
      "/users/annashch/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "#build the model -- without gradient reward (this is our baseline)\n",
    "input_shape=(200,4)\n",
    "pool_size=10 \n",
    "np.random.seed(1234)\n",
    "inp = keras.layers.Input(shape=input_shape)\n",
    "conv1 = keras.layers.Convolution1D(nb_filter=10, filter_length=10, subsample_length=1)(inp)\n",
    "relu1 = keras.layers.Activation(\"relu\")(conv1)\n",
    "#pool1=keras.layers.pooling.AveragePooling1D(pool_size=4)(relu1)\n",
    "conv2 = keras.layers.Convolution1D(nb_filter=10, filter_length=30, subsample_length=1)(relu1)\n",
    "relu2 = keras.layers.Activation(\"relu\")(conv2)\n",
    "gap = keras.layers.pooling.GlobalAveragePooling1D()(relu2)\n",
    "dense = keras.layers.Dense(2)(gap)\n",
    "sigmoid_out = keras.layers.Activation(\"sigmoid\")(dense)\n",
    "model = keras.models.Model(input=inp, output=sigmoid_out)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",metrics=[\"binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 300 samples\n",
      "Epoch 1/50\n",
      "2400/2400 [==============================] - 1s - loss: 0.6764 - binary_accuracy: 0.6110 - val_loss: 0.6559 - val_binary_accuracy: 0.6500\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6397 - binary_accuracy: 0.6679 - val_loss: 0.6584 - val_binary_accuracy: 0.6500\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6389 - binary_accuracy: 0.6679 - val_loss: 0.6480 - val_binary_accuracy: 0.6500\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6368 - binary_accuracy: 0.6679 - val_loss: 0.6479 - val_binary_accuracy: 0.6500\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6357 - binary_accuracy: 0.6679 - val_loss: 0.6485 - val_binary_accuracy: 0.6500\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6354 - binary_accuracy: 0.6679 - val_loss: 0.6483 - val_binary_accuracy: 0.6500\n",
      "Epoch 7/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6352 - binary_accuracy: 0.6679 - val_loss: 0.6475 - val_binary_accuracy: 0.6500\n",
      "Epoch 8/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6350 - binary_accuracy: 0.6679 - val_loss: 0.6476 - val_binary_accuracy: 0.6500\n",
      "Epoch 9/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6349 - binary_accuracy: 0.6679 - val_loss: 0.6469 - val_binary_accuracy: 0.6500\n",
      "Epoch 10/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6345 - binary_accuracy: 0.6679 - val_loss: 0.6474 - val_binary_accuracy: 0.6500\n",
      "Epoch 11/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6340 - binary_accuracy: 0.6679 - val_loss: 0.6462 - val_binary_accuracy: 0.6500\n",
      "Epoch 12/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6338 - binary_accuracy: 0.6679 - val_loss: 0.6468 - val_binary_accuracy: 0.6500\n",
      "Epoch 13/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6335 - binary_accuracy: 0.6679 - val_loss: 0.6457 - val_binary_accuracy: 0.6500\n",
      "Epoch 14/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6331 - binary_accuracy: 0.6679 - val_loss: 0.6453 - val_binary_accuracy: 0.6500\n",
      "Epoch 15/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6328 - binary_accuracy: 0.6679 - val_loss: 0.6454 - val_binary_accuracy: 0.6500\n",
      "Epoch 16/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6323 - binary_accuracy: 0.6679 - val_loss: 0.6437 - val_binary_accuracy: 0.6500\n",
      "Epoch 17/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6319 - binary_accuracy: 0.6679 - val_loss: 0.6435 - val_binary_accuracy: 0.6500\n",
      "Epoch 18/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6311 - binary_accuracy: 0.6679 - val_loss: 0.6425 - val_binary_accuracy: 0.6500\n",
      "Epoch 19/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6311 - binary_accuracy: 0.6679 - val_loss: 0.6425 - val_binary_accuracy: 0.6500\n",
      "Epoch 20/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6302 - binary_accuracy: 0.6679 - val_loss: 0.6411 - val_binary_accuracy: 0.6500\n",
      "Epoch 21/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6297 - binary_accuracy: 0.6679 - val_loss: 0.6402 - val_binary_accuracy: 0.6500\n",
      "Epoch 22/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6290 - binary_accuracy: 0.6679 - val_loss: 0.6389 - val_binary_accuracy: 0.6500\n",
      "Epoch 23/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6281 - binary_accuracy: 0.6679 - val_loss: 0.6385 - val_binary_accuracy: 0.6500\n",
      "Epoch 24/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6274 - binary_accuracy: 0.6679 - val_loss: 0.6369 - val_binary_accuracy: 0.6500\n",
      "Epoch 25/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6265 - binary_accuracy: 0.6679 - val_loss: 0.6348 - val_binary_accuracy: 0.6500\n",
      "Epoch 26/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6255 - binary_accuracy: 0.6679 - val_loss: 0.6337 - val_binary_accuracy: 0.6500\n",
      "Epoch 27/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6244 - binary_accuracy: 0.6679 - val_loss: 0.6326 - val_binary_accuracy: 0.6500\n",
      "Epoch 28/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6230 - binary_accuracy: 0.6679 - val_loss: 0.6303 - val_binary_accuracy: 0.6500\n",
      "Epoch 29/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6225 - binary_accuracy: 0.6679 - val_loss: 0.6274 - val_binary_accuracy: 0.6500\n",
      "Epoch 30/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6207 - binary_accuracy: 0.6679 - val_loss: 0.6254 - val_binary_accuracy: 0.6517\n",
      "Epoch 31/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6195 - binary_accuracy: 0.6694 - val_loss: 0.6253 - val_binary_accuracy: 0.6517\n",
      "Epoch 32/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6187 - binary_accuracy: 0.6696 - val_loss: 0.6206 - val_binary_accuracy: 0.6550\n",
      "Epoch 33/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6163 - binary_accuracy: 0.6685 - val_loss: 0.6192 - val_binary_accuracy: 0.6533\n",
      "Epoch 34/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6147 - binary_accuracy: 0.6708 - val_loss: 0.6172 - val_binary_accuracy: 0.6517\n",
      "Epoch 35/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6136 - binary_accuracy: 0.6706 - val_loss: 0.6144 - val_binary_accuracy: 0.6550\n",
      "Epoch 36/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6128 - binary_accuracy: 0.6767 - val_loss: 0.6127 - val_binary_accuracy: 0.6533\n",
      "Epoch 37/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6107 - binary_accuracy: 0.6762 - val_loss: 0.6103 - val_binary_accuracy: 0.6517\n",
      "Epoch 38/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6093 - binary_accuracy: 0.6754 - val_loss: 0.6071 - val_binary_accuracy: 0.6567\n",
      "Epoch 39/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6071 - binary_accuracy: 0.6763 - val_loss: 0.6055 - val_binary_accuracy: 0.6633\n",
      "Epoch 40/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6060 - binary_accuracy: 0.6804 - val_loss: 0.6031 - val_binary_accuracy: 0.6633\n",
      "Epoch 41/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6036 - binary_accuracy: 0.6804 - val_loss: 0.6021 - val_binary_accuracy: 0.6783\n",
      "Epoch 42/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6032 - binary_accuracy: 0.6821 - val_loss: 0.5986 - val_binary_accuracy: 0.6633\n",
      "Epoch 43/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.6001 - binary_accuracy: 0.6848 - val_loss: 0.5962 - val_binary_accuracy: 0.6683\n",
      "Epoch 44/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.5981 - binary_accuracy: 0.6835 - val_loss: 0.5933 - val_binary_accuracy: 0.6700\n",
      "Epoch 45/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.5961 - binary_accuracy: 0.6869 - val_loss: 0.5906 - val_binary_accuracy: 0.6683\n",
      "Epoch 46/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.5944 - binary_accuracy: 0.6842 - val_loss: 0.5936 - val_binary_accuracy: 0.6900\n",
      "Epoch 47/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.5939 - binary_accuracy: 0.6919 - val_loss: 0.5871 - val_binary_accuracy: 0.6667\n",
      "Epoch 48/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.5907 - binary_accuracy: 0.6929 - val_loss: 0.5852 - val_binary_accuracy: 0.6817\n",
      "Epoch 49/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.5882 - binary_accuracy: 0.6892 - val_loss: 0.5799 - val_binary_accuracy: 0.6817\n",
      "Epoch 50/50\n",
      "2400/2400 [==============================] - 0s - loss: 0.5854 - binary_accuracy: 0.6931 - val_loss: 0.5773 - val_binary_accuracy: 0.6867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f36e7662490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model \n",
    "model_output_path=\"benchmarkModel\"\n",
    "#checkpointer = ModelCheckpoint(filepath=model_output_path)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "tensorboard = TensorBoard( write_images=True)\n",
    "csv_logger = CSVLogger('training.benchmark.log')\n",
    "\n",
    "model.fit(x=np.asarray(train_X), \n",
    "          y=np.asarray(train_Y),\n",
    "          callbacks=[earlystopper,csv_logger,tensorboard],\n",
    "          batch_size=250,\n",
    "          epochs=50,\n",
    "          validation_data=tuple([valid_X,valid_Y]),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/annashch/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(strides=1, filters=10, kernel_size=10)`\n",
      "/users/annashch/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(strides=1, filters=10, kernel_size=30)`\n",
      "/users/annashch/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "#build the model with gradient reward \n",
    "reload(keras.losses)\n",
    "from keras.layers.merge import Grad\n",
    "input_shape=(200,4)\n",
    "pool_size=20 \n",
    "np.random.seed(1234)\n",
    "inp = keras.layers.Input(shape=input_shape)\n",
    "conv1 = keras.layers.Convolution1D(nb_filter=10, filter_length=10, subsample_length=1)(inp)\n",
    "relu1 = keras.layers.Activation(\"relu\")(conv1)\n",
    "#pool1=keras.layers.pooling.MaxPooling1D(pool_size=4)(relu1)\n",
    "conv2 = keras.layers.Convolution1D(nb_filter=10, filter_length=30, subsample_length=1)(relu1)\n",
    "relu2 = keras.layers.Activation(\"relu\")(conv2)\n",
    "gap = keras.layers.pooling.GlobalAveragePooling1D()(relu2)\n",
    "dense = keras.layers.Dense(2)(gap)\n",
    "sigmoid_out = keras.layers.Activation(\"sigmoid\")(dense)\n",
    "grad_layer1 = Grad(task_index=0)([inp, dense])\n",
    "grad_layer2 = Grad(task_index=1)([inp, dense])\n",
    "model_grad = keras.models.Model(input=inp, output=[sigmoid_out, grad_layer1,grad_layer2])\n",
    "model_grad.compile(sample_weight_mode=[None,\"temporal\",\"temporal\"],\n",
    "                   optimizer=\"adam\", \n",
    "                   loss=[\"binary_crossentropy\",\n",
    "                         keras.losses.get_positionwise_cosine_1d(pool_size=pool_size),\n",
    "                         keras.losses.get_positionwise_cosine_1d(pool_size=pool_size)],\n",
    "                   metrics=[\"binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 300 samples\n",
      "Epoch 1/50\n",
      "2400/2400 [==============================] - 0s - loss: -46.3965 - activation_42_loss: 0.6764 - grad_25_loss: -19.8506 - grad_26_loss: -27.2223 - activation_42_binary_accuracy: 0.6110 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1499 - val_activation_42_loss: 0.6559 - val_grad_25_loss: -0.3271 - val_grad_26_loss: -0.4787 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 2/50\n",
      "2400/2400 [==============================] - 0s - loss: -74.5745 - activation_42_loss: 0.6397 - grad_25_loss: -30.9093 - grad_26_loss: -44.3049 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.0708 - val_activation_42_loss: 0.6584 - val_grad_25_loss: -0.3117 - val_grad_26_loss: -0.4175 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 3/50\n",
      "2400/2400 [==============================] - 0s - loss: -79.3331 - activation_42_loss: 0.6389 - grad_25_loss: -35.8193 - grad_26_loss: -44.1527 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.2539 - val_activation_42_loss: 0.6480 - val_grad_25_loss: -0.4171 - val_grad_26_loss: -0.4849 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 4/50\n",
      "2400/2400 [==============================] - 0s - loss: -93.1555 - activation_42_loss: 0.6368 - grad_25_loss: -44.5402 - grad_26_loss: -49.2521 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.3260 - val_activation_42_loss: 0.6479 - val_grad_25_loss: -0.4773 - val_grad_26_loss: -0.4966 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 5/50\n",
      "2400/2400 [==============================] - 0s - loss: -97.7915 - activation_42_loss: 0.6357 - grad_25_loss: -49.4851 - grad_26_loss: -48.9421 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.3575 - val_activation_42_loss: 0.6485 - val_grad_25_loss: -0.5164 - val_grad_26_loss: -0.4896 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 6/50\n",
      "2400/2400 [==============================] - 0s - loss: -99.8852 - activation_42_loss: 0.6354 - grad_25_loss: -52.4750 - grad_26_loss: -48.0456 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.3749 - val_activation_42_loss: 0.6483 - val_grad_25_loss: -0.5396 - val_grad_26_loss: -0.4836 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 7/50\n",
      "2400/2400 [==============================] - 0s - loss: -102.2848 - activation_42_loss: 0.6352 - grad_25_loss: -55.0192 - grad_26_loss: -47.9008 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.3880 - val_activation_42_loss: 0.6475 - val_grad_25_loss: -0.5568 - val_grad_26_loss: -0.4787 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 8/50\n",
      "2400/2400 [==============================] - 0s - loss: -101.3015 - activation_42_loss: 0.6350 - grad_25_loss: -55.6213 - grad_26_loss: -46.3152 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.3713 - val_activation_42_loss: 0.6476 - val_grad_25_loss: -0.5587 - val_grad_26_loss: -0.4603 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 9/50\n",
      "2400/2400 [==============================] - 0s - loss: -101.3964 - activation_42_loss: 0.6349 - grad_25_loss: -56.3311 - grad_26_loss: -45.7003 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.3653 - val_activation_42_loss: 0.6469 - val_grad_25_loss: -0.5617 - val_grad_26_loss: -0.4505 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 10/50\n",
      "2400/2400 [==============================] - 0s - loss: -98.5070 - activation_42_loss: 0.6345 - grad_25_loss: -55.5444 - grad_26_loss: -43.5971 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.3298 - val_activation_42_loss: 0.6474 - val_grad_25_loss: -0.5502 - val_grad_26_loss: -0.4271 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 11/50\n",
      "2400/2400 [==============================] - 0s - loss: -96.6998 - activation_42_loss: 0.6340 - grad_25_loss: -54.9069 - grad_26_loss: -42.4270 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.3152 - val_activation_42_loss: 0.6462 - val_grad_25_loss: -0.5443 - val_grad_26_loss: -0.4171 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 12/50\n",
      "2400/2400 [==============================] - 0s - loss: -92.6361 - activation_42_loss: 0.6338 - grad_25_loss: -53.3190 - grad_26_loss: -39.9509 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.2599 - val_activation_42_loss: 0.6468 - val_grad_25_loss: -0.5246 - val_grad_26_loss: -0.3821 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 13/50\n",
      "2400/2400 [==============================] - 0s - loss: -88.4857 - activation_42_loss: 0.6335 - grad_25_loss: -51.7069 - grad_26_loss: -37.4122 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.2316 - val_activation_42_loss: 0.6457 - val_grad_25_loss: -0.5127 - val_grad_26_loss: -0.3646 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 14/50\n",
      "2400/2400 [==============================] - 0s - loss: -85.5501 - activation_42_loss: 0.6331 - grad_25_loss: -50.4797 - grad_26_loss: -35.7034 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1911 - val_activation_42_loss: 0.6453 - val_grad_25_loss: -0.4963 - val_grad_26_loss: -0.3401 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 15/50\n",
      "2400/2400 [==============================] - 0s - loss: -81.6080 - activation_42_loss: 0.6328 - grad_25_loss: -48.9535 - grad_26_loss: -33.2873 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1571 - val_activation_42_loss: 0.6454 - val_grad_25_loss: -0.4830 - val_grad_26_loss: -0.3195 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 16/50\n",
      "2400/2400 [==============================] - 0s - loss: -79.6187 - activation_42_loss: 0.6323 - grad_25_loss: -48.0981 - grad_26_loss: -32.1529 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1533 - val_activation_42_loss: 0.6437 - val_grad_25_loss: -0.4790 - val_grad_26_loss: -0.3180 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 17/50\n",
      "2400/2400 [==============================] - 0s - loss: -77.1350 - activation_42_loss: 0.6319 - grad_25_loss: -47.1064 - grad_26_loss: -30.6605 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1312 - val_activation_42_loss: 0.6435 - val_grad_25_loss: -0.4699 - val_grad_26_loss: -0.3048 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 18/50\n",
      "2400/2400 [==============================] - 0s - loss: -76.3926 - activation_42_loss: 0.6311 - grad_25_loss: -46.6175 - grad_26_loss: -30.4063 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1242 - val_activation_42_loss: 0.6425 - val_grad_25_loss: -0.4651 - val_grad_26_loss: -0.3017 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 19/50\n",
      "2400/2400 [==============================] - 0s - loss: -74.9356 - activation_42_loss: 0.6311 - grad_25_loss: -46.0574 - grad_26_loss: -29.5093 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1101 - val_activation_42_loss: 0.6425 - val_grad_25_loss: -0.4601 - val_grad_26_loss: -0.2925 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 20/50\n",
      "2400/2400 [==============================] - 0s - loss: -73.7810 - activation_42_loss: 0.6302 - grad_25_loss: -45.6054 - grad_26_loss: -28.8058 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1061 - val_activation_42_loss: 0.6411 - val_grad_25_loss: -0.4567 - val_grad_26_loss: -0.2904 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 21/50\n",
      "2400/2400 [==============================] - 0s - loss: -74.0703 - activation_42_loss: 0.6297 - grad_25_loss: -45.4579 - grad_26_loss: -29.2421 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1022 - val_activation_42_loss: 0.6402 - val_grad_25_loss: -0.4539 - val_grad_26_loss: -0.2886 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 22/50\n",
      "2400/2400 [==============================] - 0s - loss: -73.1939 - activation_42_loss: 0.6290 - grad_25_loss: -45.0997 - grad_26_loss: -28.7231 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1062 - val_activation_42_loss: 0.6389 - val_grad_25_loss: -0.4530 - val_grad_26_loss: -0.2920 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 23/50\n",
      "2400/2400 [==============================] - 0s - loss: -73.4109 - activation_42_loss: 0.6281 - grad_25_loss: -45.0363 - grad_26_loss: -29.0027 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1045 - val_activation_42_loss: 0.6385 - val_grad_25_loss: -0.4520 - val_grad_26_loss: -0.2910 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 24/50\n",
      "2400/2400 [==============================] - 0s - loss: -73.9685 - activation_42_loss: 0.6274 - grad_25_loss: -45.0586 - grad_26_loss: -29.5373 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1109 - val_activation_42_loss: 0.6369 - val_grad_25_loss: -0.4515 - val_grad_26_loss: -0.2964 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 25/50\n",
      "2400/2400 [==============================] - 0s - loss: -73.8553 - activation_42_loss: 0.6265 - grad_25_loss: -44.8894 - grad_26_loss: -29.5924 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1237 - val_activation_42_loss: 0.6348 - val_grad_25_loss: -0.4525 - val_grad_26_loss: -0.3060 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 26/50\n",
      "2400/2400 [==============================] - 0s - loss: -74.9026 - activation_42_loss: 0.6255 - grad_25_loss: -44.9899 - grad_26_loss: -30.5383 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1269 - val_activation_42_loss: 0.6337 - val_grad_25_loss: -0.4519 - val_grad_26_loss: -0.3087 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 27/50\n",
      "2400/2400 [==============================] - 0s - loss: -75.4943 - activation_42_loss: 0.6244 - grad_25_loss: -45.1107 - grad_26_loss: -31.0081 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1408 - val_activation_42_loss: 0.6326 - val_grad_25_loss: -0.4548 - val_grad_26_loss: -0.3186 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 28/50\n",
      "2400/2400 [==============================] - 0s - loss: -77.1507 - activation_42_loss: 0.6230 - grad_25_loss: -45.3218 - grad_26_loss: -32.4520 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1511 - val_activation_42_loss: 0.6303 - val_grad_25_loss: -0.4538 - val_grad_26_loss: -0.3277 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 29/50\n",
      "2400/2400 [==============================] - 0s - loss: -78.1907 - activation_42_loss: 0.6225 - grad_25_loss: -45.3040 - grad_26_loss: -33.5091 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1798 - val_activation_42_loss: 0.6274 - val_grad_25_loss: -0.4580 - val_grad_26_loss: -0.3491 - val_activation_42_binary_accuracy: 0.6500 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 30/50\n",
      "2400/2400 [==============================] - 0s - loss: -80.2614 - activation_42_loss: 0.6207 - grad_25_loss: -45.5379 - grad_26_loss: -35.3442 - activation_42_binary_accuracy: 0.6679 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.2031 - val_activation_42_loss: 0.6254 - val_grad_25_loss: -0.4606 - val_grad_26_loss: -0.3679 - val_activation_42_binary_accuracy: 0.6517 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 31/50\n",
      "2400/2400 [==============================] - 0s - loss: -82.5378 - activation_42_loss: 0.6195 - grad_25_loss: -46.0050 - grad_26_loss: -37.1523 - activation_42_binary_accuracy: 0.6694 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.2159 - val_activation_42_loss: 0.6253 - val_grad_25_loss: -0.4629 - val_grad_26_loss: -0.3783 - val_activation_42_binary_accuracy: 0.6517 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 32/50\n",
      "2400/2400 [==============================] - 0s - loss: -84.9187 - activation_42_loss: 0.6187 - grad_25_loss: -46.2410 - grad_26_loss: -39.2965 - activation_42_binary_accuracy: 0.6696 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.2591 - val_activation_42_loss: 0.6206 - val_grad_25_loss: -0.4676 - val_grad_26_loss: -0.4121 - val_activation_42_binary_accuracy: 0.6550 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 33/50\n",
      "2400/2400 [==============================] - 0s - loss: -87.1310 - activation_42_loss: 0.6163 - grad_25_loss: -46.6404 - grad_26_loss: -41.1069 - activation_42_binary_accuracy: 0.6685 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.2601 - val_activation_42_loss: 0.6192 - val_grad_25_loss: -0.4716 - val_grad_26_loss: -0.4077 - val_activation_42_binary_accuracy: 0.6533 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 34/50\n",
      "2400/2400 [==============================] - 0s - loss: -86.2587 - activation_42_loss: 0.6147 - grad_25_loss: -47.2013 - grad_26_loss: -39.6722 - activation_42_binary_accuracy: 0.6708 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.2416 - val_activation_42_loss: 0.6172 - val_grad_25_loss: -0.4766 - val_grad_26_loss: -0.3822 - val_activation_42_binary_accuracy: 0.6517 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 35/50\n",
      "2400/2400 [==============================] - 0s - loss: -81.5732 - activation_42_loss: 0.6136 - grad_25_loss: -47.6302 - grad_26_loss: -34.5565 - activation_42_binary_accuracy: 0.6706 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1596 - val_activation_42_loss: 0.6144 - val_grad_25_loss: -0.4837 - val_grad_26_loss: -0.2903 - val_activation_42_binary_accuracy: 0.6550 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 36/50\n",
      "2400/2400 [==============================] - 0s - loss: -75.9302 - activation_42_loss: 0.6128 - grad_25_loss: -48.4237 - grad_26_loss: -28.1192 - activation_42_binary_accuracy: 0.6767 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1496 - val_activation_42_loss: 0.6127 - val_grad_25_loss: -0.4882 - val_grad_26_loss: -0.2742 - val_activation_42_binary_accuracy: 0.6533 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 37/50\n",
      "2400/2400 [==============================] - 0s - loss: -74.8793 - activation_42_loss: 0.6107 - grad_25_loss: -48.9614 - grad_26_loss: -26.5286 - activation_42_binary_accuracy: 0.6763 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1466 - val_activation_42_loss: 0.6103 - val_grad_25_loss: -0.4943 - val_grad_26_loss: -0.2627 - val_activation_42_binary_accuracy: 0.6517 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 38/50\n",
      "2400/2400 [==============================] - 0s - loss: -75.1668 - activation_42_loss: 0.6093 - grad_25_loss: -49.6754 - grad_26_loss: -26.1007 - activation_42_binary_accuracy: 0.6754 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1584 - val_activation_42_loss: 0.6071 - val_grad_25_loss: -0.5034 - val_grad_26_loss: -0.2622 - val_activation_42_binary_accuracy: 0.6567 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 39/50\n",
      "2400/2400 [==============================] - 0s - loss: -75.7978 - activation_42_loss: 0.6071 - grad_25_loss: -50.3768 - grad_26_loss: -26.0282 - activation_42_binary_accuracy: 0.6762 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1595 - val_activation_42_loss: 0.6055 - val_grad_25_loss: -0.5120 - val_grad_26_loss: -0.2529 - val_activation_42_binary_accuracy: 0.6633 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 40/50\n",
      "2400/2400 [==============================] - 0s - loss: -75.6683 - activation_42_loss: 0.6060 - grad_25_loss: -51.2664 - grad_26_loss: -25.0079 - activation_42_binary_accuracy: 0.6804 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1611 - val_activation_42_loss: 0.6031 - val_grad_25_loss: -0.5196 - val_grad_26_loss: -0.2446 - val_activation_42_binary_accuracy: 0.6633 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 41/50\n",
      "2400/2400 [==============================] - 0s - loss: -74.9987 - activation_42_loss: 0.6036 - grad_25_loss: -52.0178 - grad_26_loss: -23.5845 - activation_42_binary_accuracy: 0.6804 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1520 - val_activation_42_loss: 0.6021 - val_grad_25_loss: -0.5301 - val_grad_26_loss: -0.2239 - val_activation_42_binary_accuracy: 0.6783 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 42/50\n",
      "2400/2400 [==============================] - 0s - loss: -73.7986 - activation_42_loss: 0.6032 - grad_25_loss: -52.8635 - grad_26_loss: -21.5382 - activation_42_binary_accuracy: 0.6823 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1389 - val_activation_42_loss: 0.5986 - val_grad_25_loss: -0.5349 - val_grad_26_loss: -0.2026 - val_activation_42_binary_accuracy: 0.6633 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 43/50\n",
      "2400/2400 [==============================] - 0s - loss: -73.2127 - activation_42_loss: 0.6001 - grad_25_loss: -53.6372 - grad_26_loss: -20.1757 - activation_42_binary_accuracy: 0.6848 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1433 - val_activation_42_loss: 0.5962 - val_grad_25_loss: -0.5451 - val_grad_26_loss: -0.1945 - val_activation_42_binary_accuracy: 0.6683 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 44/50\n",
      "2400/2400 [==============================] - 0s - loss: -72.5754 - activation_42_loss: 0.5981 - grad_25_loss: -54.4520 - grad_26_loss: -18.7215 - activation_42_binary_accuracy: 0.6835 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1319 - val_activation_42_loss: 0.5933 - val_grad_25_loss: -0.5536 - val_grad_26_loss: -0.1716 - val_activation_42_binary_accuracy: 0.6700 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 45/50\n",
      "2400/2400 [==============================] - 0s - loss: -71.2250 - activation_42_loss: 0.5961 - grad_25_loss: -55.3905 - grad_26_loss: -16.4307 - activation_42_binary_accuracy: 0.6869 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1204 - val_activation_42_loss: 0.5906 - val_grad_25_loss: -0.5620 - val_grad_26_loss: -0.1490 - val_activation_42_binary_accuracy: 0.6683 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 46/50\n",
      "2400/2400 [==============================] - 0s - loss: -70.3470 - activation_42_loss: 0.5944 - grad_25_loss: -56.1591 - grad_26_loss: -14.7823 - activation_42_binary_accuracy: 0.6842 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1443 - val_activation_42_loss: 0.5936 - val_grad_25_loss: -0.5759 - val_grad_26_loss: -0.1620 - val_activation_42_binary_accuracy: 0.6900 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 47/50\n",
      "2400/2400 [==============================] - 0s - loss: -71.2985 - activation_42_loss: 0.5940 - grad_25_loss: -57.2678 - grad_26_loss: -14.6247 - activation_42_binary_accuracy: 0.6919 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1100 - val_activation_42_loss: 0.5871 - val_grad_25_loss: -0.5786 - val_grad_26_loss: -0.1185 - val_activation_42_binary_accuracy: 0.6667 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 48/50\n",
      "2400/2400 [==============================] - 0s - loss: -70.6754 - activation_42_loss: 0.5907 - grad_25_loss: -58.0251 - grad_26_loss: -13.2409 - activation_42_binary_accuracy: 0.6929 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1478 - val_activation_42_loss: 0.5852 - val_grad_25_loss: -0.5911 - val_grad_26_loss: -0.1420 - val_activation_42_binary_accuracy: 0.6817 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 49/50\n",
      "2400/2400 [==============================] - 0s - loss: -70.4070 - activation_42_loss: 0.5882 - grad_25_loss: -58.7998 - grad_26_loss: -12.1954 - activation_42_binary_accuracy: 0.6892 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1395 - val_activation_42_loss: 0.5799 - val_grad_25_loss: -0.5975 - val_grad_26_loss: -0.1218 - val_activation_42_binary_accuracy: 0.6817 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n",
      "Epoch 50/50\n",
      "2400/2400 [==============================] - 0s - loss: -71.9748 - activation_42_loss: 0.5854 - grad_25_loss: -59.6762 - grad_26_loss: -12.8840 - activation_42_binary_accuracy: 0.6931 - grad_25_binary_accuracy: 0.9376 - grad_26_binary_accuracy: 0.8996 - val_loss: -0.1463 - val_activation_42_loss: 0.5773 - val_grad_25_loss: -0.6042 - val_grad_26_loss: -0.1195 - val_activation_42_binary_accuracy: 0.6867 - val_grad_25_binary_accuracy: 0.9378 - val_grad_26_binary_accuracy: 0.9035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f369d825890>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model \n",
    "model_output_path=\"gradModel\"\n",
    "#checkpointer = ModelCheckpoint(filepath=model_output_path)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "tensorboard = TensorBoard( write_images=True)\n",
    "csv_logger = CSVLogger('training.grad.log')\n",
    "model_grad.fit(x=np.asarray(train_X), \n",
    "          y=[np.asarray(train_Y),Y_grads_gata,Y_grads_tal],\n",
    "               sample_weight=[None,weights_gata*100,weights_tal*100],\n",
    "          callbacks=[csv_logger],\n",
    "               validation_data=tuple([valid_X,\n",
    "                                      [np.asarray(valid_Y),Y_grads_gata_valid,Y_grads_tal_valid],\n",
    "                                      [None,weights_gata_valid,weights_tal_valid]\n",
    "                                     ]),\n",
    "          batch_size=250,\n",
    "          epochs=50,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_233:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grad.total_loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
